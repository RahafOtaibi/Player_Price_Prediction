

# 🚀 Football Players' Price Prediction 🏆⚽

## 🌟 Project Overview

This project dives deep into the world of football data, harnessing the power of machine learning algorithms to predict and classify outcomes. Whether you're a football fan, a data scientist, or someone passionate about applying AI to real-world datasets, this project has something for you! 

We explore a **football dataset**, utilize a variety of **machine learning techniques**, and evaluate models using standard metrics to achieve the best results. From **regression** to **classification**, this project will walk you through each step, showcasing both the complexity and beauty of predictive modeling.

## 📂 Project Files

### 1. `Usecase-7 - UPDATED.ipynb`
This is your **all-in-one notebook** that handles everything from **data exploration** to **advanced machine learning models**. Inside, you'll find:
- **Data loading** and **cleaning** processes
- Visualizations that help you understand the dataset
- Regression models like **RandomForest**, **XGBoost**, and **Linear Regression**
- **Evaluation metrics** including Mean Squared Error (MSE), R2 Score, and more
- A step-by-step walk-through for both classification and regression tasks

### 2. `Usecase-7 - UL .ipynb`
This notebook is a **variant** of the first, featuring:
- Additional **data exploration** steps using **`dtale`** (commented out)
- A slightly different approach to **model selection** and **hyperparameter tuning**
- **RandomForest** and **Logistic Regression** models for a variety of use cases
- More **interactive model performance** analysis

## 🔧 Installation

To get up and running with this project, you'll need the following libraries. To ensure all dependencies are handled, install them via `pip`:

```bash
pip install -r requirements.txt
```

Here are the key libraries used in the project:
- **pandas** for data manipulation
- **numpy** for numerical calculations
- **matplotlib & seaborn** for stunning visualizations
- **scikit-learn** for machine learning algorithms and metrics
- **xgboost** for advanced boosting algorithms
- **dtale** for a more interactive exploration of the dataset (optional)

## 📊 Data

The dataset, `final_data.csv`, contains valuable insights into football statistics, and is key to generating predictive models. Ensure the file is placed in the `Data/` folder to execute the notebooks smoothly.

## 🚀 Getting Started

1. Clone or download this repository to your local machine.
2. Open the Jupyter Notebooks in **JupyterLab** or **Jupyter Notebook**.
3. Run the cells sequentially, starting with loading the dataset and ending with model evaluation.
4. Feel free to modify and experiment with the code—it's all here for you to learn and explore!

## 📈 Model Evaluation

This project is all about understanding how well different models perform on football data. Here’s what you’ll evaluate:

### **Classification Tasks** 🏅
- **Accuracy**: How well does the model predict the correct class?
- **Precision & Recall**: How good is the model at predicting the positive class?
- **F1 Score**: A combined metric of Precision and Recall.

### **Regression Tasks** ⚙️
- **Mean Squared Error (MSE)**: How close are the predicted values to actual values?
- **R2 Score**: How much variance in the data is explained by the model?
- **Mean Absolute Error (MAE)**: How far off are the predicted values in terms of absolute difference?

## 🧑‍💻 What's Inside?

The notebooks use multiple models and techniques to showcase various machine learning applications:
- **Random Forests**: A powerful ensemble method for both classification and regression tasks.
- **XGBoost**: A high-performance gradient boosting algorithm.
- **Logistic Regression**: Used here for classification tasks, predicting probabilities.
- **Linear Regression**: A simple yet effective regression technique.
- **Hyperparameter Tuning**: Explore how GridSearchCV fine-tunes the models to perfection.

## 🔍 Data Exploration

We don’t just build models—we make sure we understand the data! Here’s a quick overview of the data analysis:
- **Exploratory Data Analysis (EDA)**: Understand the structure of the dataset using visualizations.
- **Data Preprocessing**: Cleaning the data to remove any inconsistencies and handle missing values.
- **Feature Engineering**: Creating new features to improve model performance.

## 🎯 Goals & Insights

By working through this project, you will:
- Gain experience in **data preprocessing** and **exploration**.
- Build powerful predictive models using both **classification** and **regression**.
- Learn how to tune models for **improved performance**.
- Analyze model results and apply **appropriate evaluation metrics** to determine the best-performing model.

## 🏅 License

This project is licensed under the **MIT License**. Feel free to modify and use the code, and remember to give credit where it's due!
